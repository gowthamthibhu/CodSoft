{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c0d2ae69-7116-4c71-a586-7992b194c78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gowth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gowth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "937373ed-2bae-4328-8888-3d983de401dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\gowth\\OneDrive\\Desktop\\ProgrammingProjects\\CodSoft\\movie_classification\\Genre Classification Dataset\\train_data.txt\"\n",
    "train_data = pd.read_csv(train_path, sep=':::', names=['Title', 'Genre', 'Description'], engine ='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9b38fbc6-881c-4c48-af58-78cb298aa153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title    Genre  \\\n",
      "count                                          54214    54214   \n",
      "unique                                         54214       27   \n",
      "top      Nature's Fury: Storm of the Century (2006)    drama    \n",
      "freq                                               1    13613   \n",
      "\n",
      "                                              Description  \n",
      "count                                               54214  \n",
      "unique                                              54086  \n",
      "top      Grammy - music award of the American academy ...  \n",
      "freq                                                   12  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cfbf2d65-5741-47d3-b559-f47259ae24da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 54214 entries, 1 to 54214\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        54214 non-null  object\n",
      " 1   Genre        54214 non-null  object\n",
      " 2   Description  54214 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d9c1e476-fb87-43c3-9a9c-7648e0a22ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Edgar's Lunch (1998)</td>\n",
       "      <td>L.R. Brane loves his life - his car, his apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>La guerra de papá (1977)</td>\n",
       "      <td>Spain, March 1964: Quico is a very naughty ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Off the Beaten Track (2010)</td>\n",
       "      <td>One year in the life of Albin and his family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meu Amigo Hindu (2015)</td>\n",
       "      <td>His father has died, he hasn't spoken with hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Er nu zhai (1955)</td>\n",
       "      <td>Before he was known internationally as a mart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                          Title  \\\n",
       "0   1          Edgar's Lunch (1998)    \n",
       "1   2      La guerra de papá (1977)    \n",
       "2   3   Off the Beaten Track (2010)    \n",
       "3   4        Meu Amigo Hindu (2015)    \n",
       "4   5             Er nu zhai (1955)    \n",
       "\n",
       "                                         Description  \n",
       "0   L.R. Brane loves his life - his car, his apar...  \n",
       "1   Spain, March 1964: Quico is a very naughty ch...  \n",
       "2   One year in the life of Albin and his family ...  \n",
       "3   His father has died, he hasn't spoken with hi...  \n",
       "4   Before he was known internationally as a mart...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = r\"C:\\Users\\gowth\\OneDrive\\Desktop\\ProgrammingProjects\\CodSoft\\movie_classification\\Genre Classification Dataset\\test_data.txt\"\n",
    "test_data = pd.read_csv(test_path, sep=':::', names=['Id','Title','Description'], engine='python')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de012a-d85c-4952-ab87-9a4e976ffac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@\\S+', '', text)  # Remove @mentions\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'pic.\\S+', '', text)  # Remove pic links\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", '', text)  # Keep only letters and spaces\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)  # Remove single characters\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])  # Remove punctuation\n",
    "    words = nltk.word_tokenize(text)  # Tokenize the text\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    words = [stemmer.stem(word) for word in words]  # Stem the words\n",
    "    text = \" \".join(words)  # Join the words back into a single string\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "train_data['Text_cleaning'] = train_data['Description'].apply(clean_text)\n",
    "test_data['Text_cleaning'] = test_data['Description'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba73c30-b7b1-4754-9539-a5788425f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data['Text_cleaning']))\n",
    "print(len(train_data['Genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d4838-42f0-49bc-b271-96ec47ca71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(train_data['Text_cleaning'])\n",
    "X_test = tfidf_vectorizer.transform(test_data['Text_cleaning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279a887-8bed-4423-8019-0a8659f35353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['Text_cleaning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf97088-4108-4b06-bed9-7b8329e40863",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['Genre']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502e9d7-51bc-48dc-8acc-f5d5820a55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = classifier.predict(X_test)\n",
    "test_data['Predicted_Genre'] = X_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b83c92-b868-4a21-a8c6-2c5ed628a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('predicted_genres.csv', index = False)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939884ab-7c4f-45c0-b8e0-0cd5a1fe4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/tfidf_vectorizer.pkl', 'rb') as file:\n",
    "    tfidf_vectorizer = pickle.load(file)\n",
    "\n",
    "with open('model/classifier.pkl', 'rb') as file:\n",
    "    classifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f2917-1405-4b3b-95ad-de27275cf7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
